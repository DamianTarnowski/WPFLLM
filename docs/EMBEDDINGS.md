# ğŸ§  System EmbeddingÃ³w - Dokumentacja Techniczna

## PrzeglÄ…d

WPFLLM wykorzystuje lokalne modele embeddingowe z rodziny **multilingual-E5** do generowania wektorÃ³w semantycznych. System zostaÅ‚ zoptymalizowany pod kÄ…tem **wysokiej jakoÅ›ci dyskryminacji** miÄ™dzy tekstami semantycznie bliskimi i odlegÅ‚ymi.

## Architektura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LocalEmbeddingService                     â”‚
â”‚   - Inicjalizacja modelu ONNX                               â”‚
â”‚   - Prefiksy E5 (query:/passage:)                           â”‚
â”‚   - Mean pooling + L2 normalizacja                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RustTokenizer (FFI)                       â”‚
â”‚   - HuggingFace Tokenizers (Rust)                           â”‚
â”‚   - add_special_tokens = true                               â”‚
â”‚   - Automatyczne <s> i </s>                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ONNX Runtime                              â”‚
â”‚   - model.onnx (+ model.onnx_data dla large)                â”‚
â”‚   - GPU/CPU inference                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tokenizer Rust FFI

### Problem

Biblioteki .NET do tokenizacji (Microsoft.ML.Tokenizers, Tokenizers.DotNet) nie obsÅ‚ugujÄ… poprawnie parametru `add_special_tokens=true`, ktÃ³ry jest **krytyczny** dla modeli E5/XLM-RoBERTa. Bez specjalnych tokenÃ³w `<s>` (BOS) i `</s>` (EOS) embeddingi majÄ… bardzo sÅ‚abÄ… dyskryminacjÄ™.

### RozwiÄ…zanie

ZaimplementowaliÅ›my natywny tokenizer w **Rust** uÅ¼ywajÄ…c oficjalnej biblioteki HuggingFace `tokenizers`:

```rust
// TokenizerRust/src/lib.rs
#[no_mangle]
pub extern "C" fn tokenizer_encode(text: *const c_char, out_ids: *mut c_int, max_len: usize) -> c_int {
    // ...
    // KRYTYCZNE: add_special_tokens = true
    let encoding = tokenizer.encode(text_str, true)?;
    // ...
}
```

### Wyniki

| Metryka | Przed (SentencePiece .NET) | Po (Rust HuggingFace) |
|---------|---------------------------|----------------------|
| Bliskie semantycznie | 83.9% | 85.4% |
| Dalekie semantycznie | 83.2% | 70.9% |
| **GAP (dyskryminacja)** | **0.7%** âŒ | **14.5%** âœ… |

**20x lepsza dyskryminacja!**

## Pliki modelu

KaÅ¼dy model E5 wymaga nastÄ™pujÄ…cych plikÃ³w:

```
%LOCALAPPDATA%\WPFLLM\models\multilingual-e5-{size}\
â”œâ”€â”€ model.onnx           # Model ONNX
â”œâ”€â”€ model.onnx_data      # Wagi (tylko dla large, ~2GB)
â””â”€â”€ tokenizer.json       # Tokenizer HuggingFace
```

## Prefiksy E5

Modele E5 wymagajÄ… specjalnych prefiksÃ³w:

| Typ tekstu | Prefiks | PrzykÅ‚ad |
|------------|---------|----------|
| Zapytanie uÅ¼ytkownika | `query: ` | `query: Jak kupiÄ‡ samochÃ³d?` |
| Dokument/passage | `passage: ` | `passage: Porady przy zakupie auta...` |

```csharp
private string PrepareE5Text(string text, bool isQuery)
{
    var prefix = isQuery ? "query: " : "passage: ";
    if (text.StartsWith("query:") || text.StartsWith("passage:"))
        return text;
    return prefix + text;
}
```

## Mean Pooling

E5 wymaga **mean pooling** (NIE CLS pooling):

```csharp
private static float[] MeanPooling(Tensor<float> lastHiddenState, long[] attentionMask)
{
    var embedding = new float[hiddenSize];
    var sumMask = 0f;
    
    for (int i = 0; i < seqLen; i++)
    {
        if (attentionMask[i] == 1)
        {
            for (int j = 0; j < hiddenSize; j++)
                embedding[j] += lastHiddenState[0, i, j];
            sumMask += 1f;
        }
    }
    
    // Åšrednia po wszystkich tokenach
    for (int i = 0; i < hiddenSize; i++)
        embedding[i] /= sumMask;
        
    return embedding;
}
```

## Normalizacja L2

Po mean pooling stosujemy normalizacjÄ™ L2 (krytyczne dla cosine similarity):

```csharp
private static float[] L2Normalize(float[] vector)
{
    var norm = (float)Math.Sqrt(vector.Sum(x => x * x));
    if (norm < 1e-12f) return vector;
    return vector.Select(x => x / norm).ToArray();
}
```

## Modele

| Model | Wymiary | Rozmiar | JakoÅ›Ä‡ | RAM |
|-------|---------|---------|--------|-----|
| multilingual-e5-small | 384 | ~470MB | â˜…â˜…â˜…â˜†â˜† | 1-2 GB |
| multilingual-e5-base | 768 | ~1.1GB | â˜…â˜…â˜…â˜…â˜† | 2-3 GB |
| multilingual-e5-large | 1024 | ~2.2GB | â˜…â˜…â˜…â˜…â˜… | 4-6 GB |

Wszystkie modele obsÅ‚ugujÄ… **100+ jÄ™zykÃ³w** w tym polski.

## Budowanie Tokenizera Rust

```bash
cd TokenizerRust
cargo build --release
```

Wynikowy plik: `target/release/hf_tokenizer.dll` (~3.7MB)

## Checklist dla poprawnych embeddingÃ³w

- [x] Tokenizer z `tokenizer.json` (nie sentencepiece.bpe.model)
- [x] `add_special_tokens = true` (tokeny `<s>` i `</s>`)
- [x] Prefiksy `query:` / `passage:`
- [x] Mean pooling (nie CLS)
- [x] Normalizacja L2
- [x] Max sequence length: 256 (zalecane), 512 (max)

## Troubleshooting

### SÅ‚aba dyskryminacja (GAP < 5%)
1. SprawdÅº czy tokenizer dodaje specjalne tokeny (ID 0 na poczÄ…tku, ID 2 na koÅ„cu)
2. Upewnij siÄ™ Å¼e uÅ¼ywasz prefiksÃ³w `query:`/`passage:`
3. Zweryfikuj normalizacjÄ™ L2

### DllNotFoundException: hf_tokenizer
1. Skopiuj `hf_tokenizer.dll` do katalogu z aplikacjÄ…
2. Lub dodaj do projektu z `CopyToOutputDirectory`

### Wolna inference
1. UÅ¼yj mniejszego modelu (e5-small)
2. Zmniejsz `MaxSequenceLength`
3. RozwaÅ¼ GPU acceleration (ONNX Runtime CUDA)
